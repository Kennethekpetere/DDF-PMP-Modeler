{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1256cf0-383c-4dad-82e1-f3f7d098b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This notebook extracts IMERG Timeseries Precipitations (2000 - 2023) for Multi-stations. \n",
    "    \n",
    "    contact\n",
    "    ----------\n",
    "    Dr. KENNETH EKPETERE |kenneth.ekpetere@gmail.com\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f2701-ef43-444f-ab3a-c967731f766e",
   "metadata": {},
   "source": [
    "### **IMERG Multi-Stations Timeseries Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49911af6-9771-477b-b6ef-2d726843196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# import time as tm\n",
    "# from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f770c5c-9638-4e8e-a29e-a00355032d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Authenticate Earth Engine.\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a8fbb-13af-4b74-b92f-0d166c402b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Earth Engine module.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fab03-16e2-4e35-9ce9-4a8b69d3f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract IMERG time series for a given station/pixel\n",
    "def extract_imerg_time_series(lat, lon):\n",
    "    # IMERG dataset\n",
    "    dataset = ee.ImageCollection('NASA/GPM_L3/IMERG_V06').select('precipitationCal')\n",
    "\n",
    "    # Define point of interest from stn list\n",
    "    point = ee.Geometry.Point(lon, lat)\n",
    "\n",
    "    # Initialize empty list to store yearly dataframes\n",
    "    yearly_dfs = []\n",
    "\n",
    "    # Define start and end dates for yearly chunks\n",
    "    start_date = ee.Date('2000-06-03')\n",
    "    end_date = ee.Date('2023-12-31')\n",
    "\n",
    "    # Iterate over years and extract data in yearly chunks\n",
    "    year = start_date.get('year')\n",
    "    while year.getInfo() <= end_date.get('year').getInfo():\n",
    "        # Define current year's date range\n",
    "        start_year = ee.Date.fromYMD(year, 1, 1)\n",
    "        end_year = ee.Date.fromYMD(year, 12, 31)\n",
    "\n",
    "        # Filter dataset by current year\n",
    "        filtered = dataset.filterDate(start_year, end_year)\n",
    "\n",
    "        # Extract time-series at the point\n",
    "        ts = filtered.getRegion(point, scale=11132).getInfo()\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(ts[1:], columns=ts[0])\n",
    "        df = df[['time', 'precipitationCal']]\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "\n",
    "        # Append yearly DataFrame to list\n",
    "        yearly_dfs.append(df)\n",
    "\n",
    "        # Move to the next year\n",
    "        year = ee.Number(year).add(1)\n",
    "\n",
    "    # Concatenate all yearly dataframes into one\n",
    "    combined_df = pd.concat(yearly_dfs, ignore_index=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Read input CSV file\n",
    "input_file = 'test_stn.csv'  # test stations (5 - stations)\n",
    "# input_file = 'stn.csv'     # full stations (2360 - stations)\n",
    "output_folder = 'output_files/'\n",
    "\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Process each row in the CSV\n",
    "for index, row in data.iterrows():\n",
    "    unique_id = str(int(row['ID']))  # Convert ID to string\n",
    "\n",
    "    try:\n",
    "        lat = row['Lat']\n",
    "        lon = row['Lon']\n",
    "\n",
    "        # Extract IMERG time series\n",
    "        ts_df = extract_imerg_time_series(lat, lon)\n",
    "\n",
    "        # Save output to CSV\n",
    "        filename = f\"ts_{unique_id}_{lat}_{lon}.csv\"\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        ts_df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"Processed ID: {unique_id}. Saved to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ID {unique_id}: {str(e)}\")\n",
    "\n",
    "    # Pause for 5 seconds to prevent memory issues and respect GEE limitations\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"All IDs processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838fd7e-d196-4780-b1c3-47400d85dc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
